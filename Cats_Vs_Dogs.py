# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1chCjpkf5EGZS1aLLbK_zUfAd8qOlnPI2
"""

import tensorflow as tf
import tensorflow_datasets as tfds
tfds.disable_progress_bar()
import matplotlib.pyplot as plt
import numpy as np
import math

import logging
logger = tf.get_logger()
logger.setLevel(logging.ERROR)

dataset , metadata = tfds.load('cats_vs_dogs' , as_supervised = True , with_info = True)
train_dataset = tfds.load('cats_vs_dogs' , split = ['train[:70%]'] , as_supervised = True)
val_dataset = tfds.load('cats_vs_dogs' , split = ['train[70%:90%]'] , as_supervised = True)
test_dataset = tfds.load('cats_vs_dogs' , split = ['train[90%:]'] , as_supervised = True)

get_label_name = metadata.features['label'].names
print(f"Labels : {get_label_name}")

Train_samples = tf.data.experimental.cardinality(train_dataset[0]).numpy()
Val_samples = tf.data.experimental.cardinality(val_dataset[0]).numpy()
Test_samples = tf.data.experimental.cardinality(test_dataset[0]).numpy()

print(f"Number of training samples : {Train_samples}")
print(f"Number of validation samples : {Val_samples}")
print(f"Number of test samples : {Test_samples}")

def normalize(images , label):
  images = tf.image.resize(images , (150 , 150))
  images = tf.cast(images , tf.float32)/255
  return images , label

def augmentation(images , label):
  images = tf.image.random_brightness(images , max_delta = 0.1)
  images = tf.image.random_flip_left_right(images)
  return images , label

# Apply normalize to each dataset split in the dictionary
train_dataset = train_dataset[0].map(normalize).map(augmentation) # Access the first element of the list
val_dataset = val_dataset[0].map(normalize) # Access the first element of the list
test_dataset = test_dataset[0].map(normalize) # Access the first element of the list


plt.figure(figsize = (10 , 10))
for i , (image , label) in enumerate(train_dataset.take(25)):
  plt.subplot(5 , 5 , i + 1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(image , cmap = plt.cm.binary)
  plt.title(get_label_name[label]) # Use get_label_name as a list to get the label name
plt.show()

models = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32 , (3,3) , padding = 'same' , activation = 'relu' , input_shape = (150 , 150 , 3)) ,
    tf.keras.layers.MaxPooling2D((2, 2) , strides = 2),

    tf.keras.layers.Conv2D(64 , (3,3) , padding = 'same' , activation = 'relu'),
    tf.keras.layers.MaxPooling2D((2, 2) , strides = 2),

    tf.keras.layers.Conv2D(128 , (3,3) , padding = 'same' , activation = 'relu'),
    tf.keras.layers.MaxPooling2D((2, 2) , strides = 2),

    tf.keras.layers.Conv2D(128 , (3,3) , padding = 'same' , activation = 'relu'),
    tf.keras.layers.MaxPooling2D((2, 2) , strides = 2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512 , activation = 'relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1 , activation = 'sigmoid')

])

models.compile(optimizer = 'adam' , loss = tf.keras.losses.BinaryCrossentropy() , metrics = ['accuracy'])

BATCH_SIZE = 32

train_dataset = train_dataset.shuffle(Train_samples/BATCH_SIZE).batch(BATCH_SIZE)
val_dataset = val_dataset.shuffle(Val_samples/BATCH_SIZE).batch(BATCH_SIZE)
test_dataset = test_dataset.batch(BATCH_SIZE)
EPOCHS = 10
history = models.fit(train_dataset , epochs = EPOCHS , steps_per_epoch = math.ceil(Train_samples/BATCH_SIZE) , validation_data = val_dataset , validation_steps = math.ceil(Val_samples/BATCH_SIZE))

test_loss , test_accuracy = models.evaluate(test_dataset)
print(f"Test Loss : {test_loss}")
print(f"Test Accuracy : {test_accuracy}")

epochs_range = range(EPOCHS)
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize(8,8))
plt.subplot(1,2,1)
plt.plot(epochs_range , acc , label = 'Training Accuracy')
plt.plot(epochs_range , val_acc , label = 'Validation Accuracy')
plt.legend(loc = 'lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1,2,2)
plt.plot(epochs_range , loss , label = 'Training Loss')
plt.plot(epochs_range , val_loss , label = 'Validation Loss')
plt.legend(loc = 'upper right')
plt.title('Training and Validation Loss')
plt.show()